version: '3.8'

services:
  hf-downloader:
    image: hf-downloader:latest  # Use pre-built image
    container_name: hf-model-downloader
    ports:
      - "5000:5000"  # Single port for both interfaces
    volumes:
      - ./models:/models:rw  # Mount models directory
      - hf-cache:/home/appuser/.cache/huggingface  # Cache HuggingFace models
    environment:
      - HF_HUB_ENABLE_HF_TRANSFER=1
      # Multi-process architecture - no Gunicorn needed
      # - GUNICORN_CMD_ARGS removed for multi-process mode
      # Optional: Add your HuggingFace token for private models
      # - HF_TOKEN=your_hf_token_here
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    # Resource limits (adjust based on your needs)
    # Increased CPU limit for multi-process architecture
    deploy:
      resources:
        limits:
          cpus: '4.0'  # More CPU for 4 processes
          memory: 6G   # More memory for process isolation
        reservations:
          cpus: '1.0'  # Higher reservation for stable performance
          memory: 1G

volumes:
  hf-cache:
    driver: local
